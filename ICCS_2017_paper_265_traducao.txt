Resumo
A geração de dados em massa tem impulsionado avanços nas arquiteturas de computação, refletindo nas arquiteturas heterogênias, compostas por diferentes tipos de unidades de processamento. O paradigma filtro-fluxo é tipicamente usado para explorar o poder de processamento paralelo de novas arquiteturas e a eficiencia das aplicações é alcançada explorando, de forma coordenada, um grupo de computadores interligados (cluster) usando filtros e comunicação entre eles. Neste trabalho propomos implementar e testar uma abstração genérica para a troca de dados direta e transparente de aplicações filtro-fluxo em cluster heterogênio com múltiplas arquiteturas GPU (Unidade de Processamento Gráfico). Esta abstração permite que todos os detalhes de implementação de baixo nível relacionados à comunicação da GPU e o controle relacionado à localização dos filtros sejam realizados de forma transparente para os programadores. Este trabalho está consolidado em um framework e nossos resultados de avaliação mostram que ele fornece uma camada de abstração sem comprometer o desempenho geral da aplicação. 
Abrstract
The massive data generation has been pushing for significant advances in computing architectures, reflecting in heterogeneous architectures, composed by different types of processing units. The filtro-fluxo paradigm is typically used to exploit the parallel processing power of these new architectures and the efficiency of applications is achieved by exploring in a coordinated way a set of interconnected computers (cluster) using filters and communication between them. In this work we propose, implement and test a generic abstraction for direct and transparent data exchange of filtro-fluxo applications in heterogeneous cluster with multi-GPU (Graphics Processing Units) architectures. This abstraction allows all the low-level implementation details related to GPU communication and the control related to the location of the filters to be performed transparently to the programmers. This work is consolidated in a framework and our evaluation results show that it provides an abstraction layer without compromising the overall application performance.
Palavras-chave:
Múltiplas GPUs, Aplicações filtro-fluxo, Arquiteturas Heterogêneas
1 - Introdução
O desenvolvimento de novas tecnologias tem sido caracterizado pela geração de dados em massa. O crescimento contínuo dos dados, associado com um processamento mais sofisticado em diferentes áreas, tem impusionado avanços significativos nas arquiteturas de computação, refletindo em sistemas de armazenamento mais eficientes, assim como o uso de diferentes tipos de unidades de processamento, nas chamadas arquiteturas heterogêneas. Um exemplo dessas novas arquiteturas são os computadores com múltiplos processadores (arquitetura multicore) e placas gráficas (utilizando a arquitetura CUDA [12], por exemplo). Neste contexto, em adição para as tradicionais interfaces de programação paralela multicore [8,10], vemos recentemente a popularização de novas bibliotecas e ambientes [12,15,18] que permitem o desenvolvimento de aplicações em unidades de processamento alternativas como as Unidades de Processamento Gráfico (GPUs). Estes avanços tem sido essenciais para permitir que diferentes algoritmos explorarem o poder do processamento paralelo nessas novas arquiteturas, tornando-os viáveis para grandes volumes de dados.
      Apesar desses avanços, existem cenários em que uma única implementação paralela não é suficiente. Exemplos desses cenários são aplicações compostas de diferentes passos de processamento, como segmentação de imagens e descoberta de conhecimento em banco de dados [3], onde cada passo recebe uma determinada entrada e produz uma saída que será usada como entrada para outra etapa. Estas aplicações são tipicamente modeladas usando o paradigma filtro-fluxo [1], cujos passos do processamento são representados por filtros, que são instanciados em uma ou mais máquinas, e os dados que passam entre estes passos são representados pelo fluxo de dados (data streams). A eficiencia das aplicações implementadas usando o paradigma filtro-fluxo é alcançada, principalmente, pela distribuição paralela desses filtros, explorando de forma coordenada o conjunto de computadores interligados (computação em cluster). Consequentemente, a performace dessas aplicações está diretamente dependente de uma comunicação eficiente entre os filtros.
    Tradicionalmente, na execução de ambientes filtro-fluxo encontradas na literatura, a comunicação é feita principalmente utilizando o Message Passing Interface (MPI) [10]. O padrão MPI mostrou ser eficiente na maioria dos cenários de filtro-fluxo e pode ser aplicado à comunicação entre filtros instânciados na mesma máquina ou em diferentes máquinas. Entretanto, quando o cluster usado para executar uma aplicação possui máquinas heterogêneas, em que um filtro particular pode ser processado em uma GPU por exemplo, a comunicação via MPI entre os filtros pode exigir algum movimento extra de dados para ser concluída. Neste caso, os dados a serem transmitidos devem ser primeiro transferidos da memória global da GPU para a memória principal do computador e, em seguida, enviados via MPI para o filtro de destino. Movimento similar pode ocorrer no filtro de destino se este também for processado em uma GPU. Estes movimentos extras entre memória das unidades de processamento pode comprometer a performace da aplicação. Até onde conhecemos, nenhum ambiente de programação paralela de filtro-fluxo permite a comunicação direta entre GPUs.
    A fim de evitar estes movimentos excecivos, as GPUs responsáveis pelo processamento dos filtros precisam ser capazes de se comunicarem diretamente, sem precisar copiar os dados para a memória da CPU. Na literatura existem estratégias que fazem essa comunicação direta entre GPUs ser possível, como por exemplo: (i) GPUDirect RDMA [14] para transferir dados entre GPUs localizadas em uma mesma máquina; (ii) Cuda Aware MPI (OpenMPI + GPUDirect RDMA) [19] focada principalmente na comunicação entre GPUs em diferentes máquinas. Além disso, no cenário filtro-fluxo, essa comunicação direta é um grande desafio, uma vez que os filtros podem ser instanciados na mesma máquina ou em máquinas diferentes, tornando o programador responsável por controlar onde cada filtro é instanciado e decidindo qual a estratégia a ser usada para executar a comunicação entre os filtros executando em diferentes GPUs.  Além de ser um controle manual para o programador, é uma abordagem que precisa ser ajustada e reimplementada a cada nova configuração de local de filtro.
	Portanto, neste trabalho propomos uma abstração genérica para troca de dados direta entre GPUs em cenários filtro-fluxo. Nossa proposta torna transparente para o programador os detalhes de implementação de baixo nível relacionados à comunicação GPU e além disso retira do programador a responsabilidade de controlar a localizados dos filtros e de escolher qual estratégia de comunicação utilizar. Consolidamos nossa proposta como um framework filtro-fluxo, que também fornece um API para auxiliar na implementação dos filtros, bem como estabelecendo um padrão para representar o fluxo de dados entre os filtros. Em nossa avaliação, nós primeiro comparamos diferentes estratégias de comunicação entre GPUs, tanto intra-node (GPUs em um mesmo computador) quanto inter-node (GPUs em computadores diferentes), com objetivo de justificar as escolhas feitas para o framework. Então, avaliamos a eficiencia de nossa poposta implementando uma aplicação real usando nosso framework. Comparando esta implementação com uma usando diretamente as tecnologias existentes para alterar dados entre GPUs, mostramos que o tempo da aplicação real é o mesmo para ambas implementações.Este fato demonstra que nossa proposta, além de fornecer uma camada de abstração para facilitar o processo de programação, bem como controlar automaticamente a instanciação dos filtros, não compromete a performace da aplicação, que corresponde à nossa maior contribuição.

2 - Trabalhos relacionados
	O paradigma filtro-fluxo [1] é uma ferramenta importante para auxiliar o desenvolvimento eficiente de uma variedade de aplicações, tais como segmentação de imagem e descoberta de conhecimento em banco de dados [3], em sistemas distribuídos. Este paradigma é apto à trabalhar, de forma corrdenada, com um conjunto de computadores interligados (computação em cluster), explorando a performace individual de cada computador, como também a contribuição paralela entre eles. Para modelar  uma aplicação no paradigma filtro-fluxo, os estágios são representados por filtros que podem ser instanciados em um ou mais computadores. Por sua vez, o fluxo consiste da comunicação entre os filtros, enviando e recebendo dados relacionados àos diferentes estágios da aplicação. Neste trabalho, estamos focados em uma solução para este nicho de aplicação.
	Podemos encontrar na literatura varias propostas de ambientes que fornecem eficientes ferramente para lidar com diferentes desafios relacionados à implementação desta categoria de aplicação, taís como gerenciamento de instanciação de filtros, comunicação entre filtros, etc [9,6,2]. No citede2011watershed é apresentado o Watershed, um ambiente filtro-fluxo que fornece uma API C++ para a implementação de cada filtro. Além disso, a troca de dados entre filtros pode ser descrita usando arquivos XML (eXtensible Markup Language). Além do mais, nestes arquivos XML é possível configurar quais computadores serão responsáveis por executar cada filtro. Assim sendo, Wathershed consiste em um ambiente completo de execução em que os programadores podem apenas carregar os arquivos de configuração e os filtros implementados, toda a execução é realizada de forma transparente. Proposta similar é apresentada em [6], o Datacuter, com praticamente as mesmas funcionalidades. Finalmente, em [2], é proposto um sistema que permite salvar o estado das aplicações em sistemas distribuídos, explorando configurações dinâmicas em um cluster. Neste artigo, não estamos propondo um ambiente completo como os descritos neste parágrafo. Entretanto, nossa abstração genérica para troca direta de dados entre GPUs em cenários filtro-fluxo pode ser adaptada para estes propositos.
	Recentemente, a paralelização de aplicações utilizando GPUs tem sido apresentada  como uma área promissora de pesquisa [13,11,5,17]. Apesar disso, em cenários de aplicação filtro-fluxo, pelo que conhecemos, não encontramos frameworks de execução filtro-fluxo que permitem uso das GPUs. Isso ocorre devido as limitações relacionadas à tecnologias existentes para compartilhar dados de forma eficiente entre diferente s GPUs: a necessidade de detalhes de implementação de baixo nível relacionados à comunicação GPU e a complexidade para controlar a instanciação de filtros. Aqui estão, basicamente, duas maneiras diferentes para lidar com essa questão: (1) estrategias intra-node; que são exclusivamente focadas no compartilhamento de dados entre GPUs presentes em um mesmo computador [7,16,20]; e (2) estratégias inter-node, focada em soluções para GPUs presentes em diferentes computadores [14,4,19].
	A respeito das estratégias intra-node, uma tecnologia comum utilizada é a Unified Virtual Adressing (UVA), que permite diferentes unidades de processamento (ou seja, CPU e GPU) acessarem o mesmo espaço de endereço de memória, reduzindo o total de cópias de memória. Em [16] é apresentado uma otimização na qual os dados que estão em diferetes espaços de endereço são encapsulados em um único objeto com o objetivo de melhorar a performace de aplicações com intenso acesso à memoria. Além disso, em [20],os autores apresentam um novo sistema para realocar memoria em clusters baseado em um conceito de único espaço de endereço. Recentemente, a implementação deste conceito especificamente para alteração de dados entre GPUs foi melhorado pela GPUDirect RDMA [14], uma nova tecnologia que permitiu a troca de dados diretamente pelo barramento da PCI Express. Em [7] os autores apresentam um estudo detalhado da performace desta tecnologia. Usando aplicações reais, como aplicações de processamento de imagens e simulações matemáticas, diferentes aspectos são avaliados em que as aplicações obtiveram bons resultados em termos de eficienca, associados com uma implementação simples.
	As abordagens relacionadas ao inter-node [4,19] são baseadas em uma combinação da tecnologia GPUDirect RDMA e implementações do padrão MPI [10], tal como o OpenMPI (ou seja, Cuda-aware MPI). Nessas abordagens, em vez de utilizar o barramento PCI Express para troca de dados entre GPUs, a interface de rede é utilizada e o processo de comunicação entre diferentes computadores é realizado pelo OpenMPI.Em [4], os autores preparam um teste que foi usado com o fim de avaliar diferentes estradegias para transferencia de dados entre GPUs presentes em diferentes computadores. A avaliação foi realizada em um cluster de banda infinita e os resultados mostram que a combinação da tecnologia GPUDirect RDMA e OpenMPI acrescentou 50% mais eficiencias comparadas as outras estratégias.
	Neste trabalho propomos e avaliamos uma abstração genérica para troca direta de dados entre GPUs em cenários filtro-fluxo que visa controlar onde cada filtro é instanciado, decidindo qual estratégia será usada para melhorar a comunicação.

3 - Framework
	Nesta seção detalhamos nossa proposta de uma abstração genérica para troca direta de dados entre GPUs em cenários filtro-fluxo que é consolidada em um framework. Primeiro apresentamos uma visão geral da arquitetura do nosso framework, seguido por detalhes relacionados à API proposta para auxiliar na implementação e configuração dos filtros. Finalmente, descrevemos o motor do framework.
3.1 - Visão geral
	[FIGURA 1]
	Na figura 1(a) apresentamos a aplicação que será ustilizada como um exemplo de base para discução nesta seção. Esta aplicação contém quatro filtros. O primeiro filtro carrega os dados e realiza o processamento inicial. Depois, os dados são enviados para os filtros 2 e 3, que realizam um processamento independente nestes mesmo conjunto de dados de entrada. Neste ponto,  estes filtros podem ser executados em paralelo, uma vez que o processamento de dados é independente. Além disso, a troca de dados realizada pelos filtros 1 e 2 é local, enquanto que a troca de dados entre os filtros 2 e 3 dependem de tranferencias na rede. Quando estes filtros terminam de processar seus dados, eles são enviados para o último filtro, que realiza a operação final nos dados recebidos. Este último filtro depende de mais de um dos filtros anteriores (2 e 3), por isso é necessário esperar por todos os filtros anteriores para enviar seus dados. Também observe que cada filtro pode executar pré ou pós operações de processamento, enquanto ele espera os dados chegarem ou  depois que estes dados são enviados para o próximo.
	O framework é separado entre duas partes principais. Primeiro, nos temos uma API, que provê uma biblioteca de funções definidas para comunicação entre os filtros, bem como um arquivo de configuração XML para ser usado pelo programador para definir os ambientes de execução (ou seja, os filtros, o diretório onde os filtros estão armazenados, os endereços de IP das máquinas disponíveis e o número de GPUs disponíveis em cada uma dessas máquinas). Toda essa configuração é usada pelo motor do framework , que é responsável por compilar, alocar e executar os filtros da aplicação. Depois da definição do código dos filtros e configuração do ambiente, o motor compila cada filtro como uma biblioteca dinâmica, e então executa a aplicação em um ambiente específico. O motor é então, responsável por cuidar do escalonamento e tarefas de comunicação. Na figura 1(b), ilustramos a arquitetura do nosso framework. Cada filtro é uma função independente, contendo um ou mais núcleos de GPU, e os fluxos são definidos pelos dados que seguem entre cada filtro.
3.2 - API do Framework
3.2.1 - Definindo os Filtros
	Para usar o framework, o programador precisa implementar cada filtro em C++, salvando cada um deles em arquivos de origem separados. Os dados processados são indendentes: cada filtro recebe estes dados, realiza seu pré-processamento (se necessário) e continua para processar os dados. No final, ele envia os dados para o próximo filtro. As tarefas de recebimento e envio dos dados são realizadas sobre as funções fornecidas pela API do framework. Listágem 1 mostra as assinaturas das funções para envio (sendMessage) e recebimento (recvMessage) de mensagens. A assinatura das duas funções é similar, recebendo como parâmetros o nome de um filtro de origem, o nome de um filtro de destino, o tipo de dado para ser enviado e o dado para ser transmitido (buffer) e seu tamanho. A necessidade de trabalhar em pares, onde a mensagem enviada por um filtro precisa ser recebida por outro. Baseado nessa informação bem como na informação da configuração de ambiente, o motor reconhece onde cada filtro e dados estão localizados e faz as transferencias quando necessário.
[LISTAGEM 1] - Chamadas das funções para envio e recebimento de mensagens com nossa API
	Listagem 2 fornece um exemplo de um filtro implementado utilizando a API. A função myFilter é responsável por receber os dados de entrada. A função então invoca o kernel da GPU para o processamento dos dados. No final, a mensagem é enviada para o próximo filtro. Essa mensagem contém os dados processados pelo filtro atual, que irá ser a entrada do próximo. A etapa de comunicação é opcional, pois depende da existentencia dos dados pré-processados por um filtro anterior ou da necessidade de enviar os dados para um próximo filtro. 
[LISTAGEM 2] - Único filtro implementado usando a API do framework. Note que os evios e recebimentos são opcionais, visto que isso depende da existência de filtros antes ou depois. 
3.2.2 - Processo de Comunicação
	A principal contribuição do framework proposto é a independencia da localização dos dados espaciais. As funções fornecidas pela API automaticamente reconhece se os dados estão na GPU ou na CPU, como também se eles estão no mesmo nodo ou não, e então realiza a transferencia dos dados. Além disso, elas atuam como barreiras entre as execuções dos filtros cujas entradas são saídas de filtros anteriores. No exemplo de base, enquanto a transferencia de dados entre os filtros 1 e 2 podem ocorrer usando uma tecnologia intra-node (ou seja, GPUDirect RDMA), a comunicação entre os filtros 1 e 3 precisa ser realizada usando uma rede (ou seja, Cuda-aware MPI).
	Para a comunicação entre GPUs no mesmo nodo, existem, basicamente, duas estratégias. A primeira é usar o motor provido pela CUDA API, fazendo copias de dados da primeira GPU para a principal memória da CPU e então copiando estes dados de volta para o endereço de memória da segunda GPU, que chamamos de Standard Communication through CPU Memory. A segunda é baseada em GPUDirect RDMA, tecnologia, introduzida no CUDA 5.0, isso permite acesso direto entre a GPU e um terceiro dispositivo através do barramento PCI-Express, que poderia ser outra GPU, interface de rede ou dispositivos de armazenamento. Entretanto, o uso dessa tecnologia é limitado ao hardware atual, ou seja, se os dispositivos não estiverem conectados via um barramento PCI-Express, essa funcionalidade não será ativada.
	No caso  de GPUs em diferentes nodos, a comunicação pode ser executada por duas estratégias. Na primeira, que chamamos de MPI Standard communication, ela faz uma cópia dos dados da primeira GPU para a memória principal da CPU e então enviando estes dados através do MPI para a segunda máquina, onde os dados serão copiados de volta para o endereço de memória na segunda GPU. A segunda é a tecnologia CUDA-aware MPI, em que o MPI pode reconhecer as GPUs e realizar as cópias de forma eficiente através da GPUDirect RDMA . Com isso, será possivel ativar a cópia de dados entre GPUs em diferentes máquinas sem passar pelo controlador de memória principal. Os dados deixam uma GPU direta para a interface de rede, é enviada para a máquina de destino e, em seguida, copiados diretamente para a GPU de destino. Essa estratégia também pode ser usada para a transferência de dados em um mesmo nodo, desde que o OpenMPI (implementação MPI usada neste trabalho) possa também utilizar o barramento de dados em vez de utilizar a interface de rede.
    Como apresentaremos na seção 4, realizamos uma série de testes para avaliar as diferentes estratégias de comunicação descritas acima, intra-node (Standart Communication through CPU Memory, GPUDirect RDMA e CUDA-aware MPI) ou inter-node (MPI Standard communication e CUDA-aware MPI). Após de avaliar os resultados, optamos por simplificar o processo de comunicação dos dados entre as GPUs do nosso framework, adotando sempre uma estratégia que usa o CUDA-aware MPI, inclusive em transferências na mesma GPU.
3.2.3 Configuração de Ambiente
    Finalmente, a configuração de ambiente que será usada pela aplicação precisa também ser passado para o motor. Para isso, usamos um arquivo XML contendo a informação necessária pelo motor. A Listagem 3 mostra um exemplo de configuração de ambiente. A configuração é simples e precisa conter informação sobre cada filtro, o diretório de instalação do framework e as máquinas que à serem usadas.
    A configuração de filtro está dentro do campo <modules>. O sub-campo <file> define o arquivo que contém o código fonte para o filtro. O sub-campo <func> define o nome da função que implementa aquele filtro. Os subcampos <include> e <libraries> indicam pastas e bibliotecas para serem incluidas para a compilação correta do filtro como uma biblioteca dinâmica. O campo <home> apenas indica a pasta onde o framework está alocado. O campo <machine> provê a informação requerida sobre o ambiente de execução. O sub-campo <ipmachine> contém o endereço de IP de cada máquina para ser usada, assim como o número de GPUs disponíveis naquela máquina. Baseado neste arquivo XML de configuração, o motor pode realizar as tarefas necessárias para execução correta da aplicação.
[LISTAGEM 3] - Arquivo de configuração
3.3 - Motor do Framework
    O motor é responsável por instanciar os filtros em cada máquina presente no arquivo de configuração, além de implementar a comunicação usada na aplicação. Para isso, ele recebe como entrada os códigos fontes dos filtros e o arquivo XML de configuração. A primeira etapa é compilar os filtros como bibliotecas dinâmicas, permitindo cada filtro ser carregado dinamicamente pelo motor.
    O próximo passo é configurar os processos de execução, que serão executados usando os parâmetros do arquivo de configuração. Como mensionado anteriormente, para as duas formas de comunicação (intra-node e inter-node), nós adotamos o CUDA-aware MPI. Dessa forma, o número de filtros definido no arquivo será usado para criar os processos MPI com diferentes níveis. Até este momento, cada filtro recebe então um único nível, que será usado para o gerenciamento da comunicação. Depois, as máquinas disponíveis e o número de GPUs em cada uma são identificados. Com essa informação, cada processo pe associado com uma única GPU, usando a função setCudaDevice presente na biblioteca do CUDA.
    Neste estágio, começa a aplicação. O motor controla a comunicação entre cada processo. Como cada filtro possui um nome especificado em um arquivo de configuração, além de um único nível do seu processo MPI, a tradução das funções da API em chamadas MPI é feita diretamente. Cada filtro executa em um processo MPI, com esse fluxo de execução modelado através de barreiras entre cópia de dados, definido pelas chamadas da API do framework. A Figura 1(a) mostra o mapeamento dos níveis dos processos e suas respectivas GPU. O Filtro 1, por exemplo, está rodando no computador 0, possui nível 0, e o ID desta GPU também é 0. Todos os filtros executam no mesmo tempo em que a aplicação começa e esperam enquanto os dados estão dispobíveis.
4 - Avaliação Experimental e Discussões 
    Nesta seção mostraremos e discutiremos os experimentos computacionais que conduziram a decisão sobre qual estratégia de comunicação utilizar no nosso framework. Além disso, usando uma aplicação real relacionada a simulações matemáticas, avaliamos o impacto da camada de abstração na performace da apliação. Todos os explerimentos apresentados nesta seção foram realizados usando dois nodos GNU/Linux 4.1.13: (1) uma maquina com um processador Intel(R) Core(TM) i7-6700 3,40GHz, 32GB de memória e duas GPUs NVIDIA Geforce GTX 1070; (2) uma máquina com um processador Intel(R) Core(TM) i5-3370 3,40GHz, 16GB de memória e uma GPU NVIDIA GeForce GT 640.
4.1 Avaliação das estratégias de comunicação
    Neste conjunto de experimentos analizamos o impacto das decisões das estratégias de comunicação na performace do nosso framework. Mais especificamente, para a comunicação intra-node avaliamos a Standard Communication through CPU Memory, a tecnologia GPUDirect RDMA e CUDA-aware MPI technology. Para a comunicação inter-node avaliamos a MPI Standard Communication e a Cuda-aware MPI technology. Realizamos experimentos analizando o overhead causado pela transferência de dados entre GPUs onde os fintros estão executando. Enviamos dados variando entre 50MB à 300MB entre os dispositivos usando as estratégias acima. Realizamos 30 execuções para cada um dos testes propostos, a fim de extrair a média e o desvio padrão para uma melhor análise dos resultados. Os resultados destes experimentos estão apresentados na Figura 2.
[Figura 2]: Avaliação das estratégias de comunicação. Estratégia CUDA-aware MPI apresenta melhores resultados em ambos cenários.
    Focando primeiro nos testes intra-node, apresentado na Figura 2(a). A estratégia CUDA-aware MPI mostrou ser mais eficiente para a comunicação entre GPUs intra-node, principalmente para dados menores, apresentando uma redução de até 10,9% no tempo de execução comparado com a estratégia GPUDirect RDMA, que foi o segundo melhor. Primeiramente, este resultado poderia ser considerado uma surpresa, já que o CUDA-aware MPI é baseado no GPUDirect RDMA, como explicado na Seção 3.2.2. Entretando, lendo a extensa documentação ao OpenMPI (https://www.open-mpi.org/), é mencionado que a biblioteca OpenMPI faz uso do suporte CUDA IPC onde é possível mover os dados da GPU facilmente entre GPUs que estão no mesmo nodo e mesmo complexo de raiz PCI, usando algumas otimizações de empacotamento de dados. Como incrementados o tamanho dos dados a serem transferidos, o tempo gasto para comunicar usando o CUDA-Aware MPI cresce mais rápido do que outras estratégias, uma vez que o total de chamadas de funções MPI tambem aumentam. Entretanto, é importante apontar o apesar disso, a performace do CUDA-aware MPI continua melhor do que outras estratégias.
    A respeito das transferencias inter-node entre GPUs, os resultados estão apresentados na Figura 2(b), apresentando resultados similares para escolha de estratégias intra-node, mas com adição do everhead da comunicação de rede. Como esperado, a implementação usando CUDA-aware MPI mostrou melhor tempo de execução. A diferença entre essass estratégias foi pequena, apresentando redução de apenas 2% comparado com a estratégia usando MPI Standard Communication. Esses resultados justificam nossa escolha para sempre usar o CUDA-aware MPI como nossa estratégia de comunicação, independentemente do local da GPU (intra-node ou inter-node).
4.2 - Avaliação do Impacto da Performance da Aplicação
    Nessa seção nosso objetivo é avaliar o impacto da camada de abstração do nosso framework na performace da aplicação. Para fazer isso, consideramos uma aplicação real relacionada à algebra linear que consiste no filtro que gera uma matriz esparsa tridiagonal A e um vetor b e envia isso para outro filtro que resolve, usando o método do gradiente conjugado, o sistema linear representado pela metriz (Ax = b). O filtro de resolução, então envia o resultado (x) para outro filtro que resolverá o sistema novamente utilizando o resultado recebido como o lado esquerdo (b) de um novo sistema. Na figura 4 ilustramos a descrição da aplicação.
[FIGURA 3] - Configuração do Filtro de uma Aplicação Real da Álgebra Linear
    Nesta avaliação consideramos duas implementações da aplicação acima: (1) uma completamente implementada utilizando nosso framework (Implementação com Framework), sem qualquer preocupação com a instanciação dos filtros e comunicação deles; e (2) uma Implementação Manual, utilizando as funções relacionadas ao CUDA-aware MPI, alocando os filtros e realizando a comunicação manualmente. Nosso objetivo não é demonstrar que a performance do nosso framework é melhor que a implementação manual, uma vez que seu desempenho é limitado pelas tecnologias adotadas. Os resultados relacionados à essa avaliação estão apresentados na Figura 4. Como podemos observar, o everhead relacionado à camada de abstração é muito pequeno, a performace de ambas implementações é praticamente equivalente. Os resultados demonstram isso, apesar do overhead relacionado à camada de abstração criada para facilitar o processo de programação, bem como controlar automaticamente a instanciação dos filtros, a performace geral da aplicação não foi comprometida.
[FIGURA 4] - Impacto da Camada de Abstração na Performace da Aplicação. Como podemos ver, nosso framework não comprometeu a performace geral da aplicação.
5 - Conclusão e Trabalhos Futuros
    Neste trabalho nós propomos, implementamos e testamos uma abstração genérica para a troca direta e transparente de dados entre GPUs em cenários filtro-fluxo em um cluster heterôgenio, composto por nodos com múltiplas GPUs. Essa abstração permite que todas os detalhes de implemetações de baixo nível relacionados à comunicação com a GPU e o controle relacionado à localização dos filtros sejam feitos de forma transparente aos programadores, reduzindo suas responsabilidades e permitindo focarem nos detalhes sobre o problema que está sendo resolvido. Depois de avaliar várias estratégias de comunicação possíveis, mostramos que nosso proposta, além de fornecer uma camada de abstração para falitar o processo de programação, além de controlar automáticamente a instanciação dos filtros, não compromete a performace geral da aplicação. Como trabalhos futuros pretendemos juntar nosso framework em um ambiente filtro-fluxo completo, tais como Watershed [9]. Também pretendemos melhorar nosso framework, permitindo ele verificar se as GPUs disponíveis possuem suporte para utilizar o GPUDirect RDMA, e caso não possuam, escolher a melhor opção disponível para aquele hardware.
