Resumo
A geração de dados em massa tem impulsionado avanços nas arquiteturas de computação, refletindo nas arquiteturas heterogênias, compostas por diferentes tipos de unidades de processamento. O paradigma filtro-fluxo é tipicamente usado para explorar o poder de processamento paralelo de novas arquiteturas e a eficiencia das aplicações é alcançada explorando, de forma coordenada, um grupo de computadores interligados (cluster) usando filtros e comunicação entre eles. Neste trabalho propomos implementar e testar uma abstração genérica para a troca de dados direta e transparente de aplicações filtro-fluxo em cluster heterogênio com múltiplas arquiteturas GPU (Unidade de Processamento Gráfico). Esta abstração permite que todos os detalhes de implementação de baixo nível relacionados à comunicação da GPU e o controle relacionado à localização dos filtros sejam realizados de forma transparente para os programadores. Este trabalho está consolidado em um framework e nossos resultados de avaliação mostram que ele fornece uma camada de abstração sem comprometer o desempenho geral da aplicação. 
Abrstract
The massive data generation has been pushing for significant advances in computing architectures, reflecting in heterogeneous architectures, composed by different types of processing units. The filtro-fluxo paradigm is typically used to exploit the parallel processing power of these new architectures and the efficiency of applications is achieved by exploring in a coordinated way a set of interconnected computers (cluster) using filters and communication between them. In this work we propose, implement and test a generic abstraction for direct and transparent data exchange of filtro-fluxo applications in heterogeneous cluster with multi-GPU (Graphics Processing Units) architectures. This abstraction allows all the low-level implementation details related to GPU communication and the control related to the location of the filters to be performed transparently to the programmers. This work is consolidated in a framework and our evaluation results show that it provides an abstraction layer without compromising the overall application performance.
Palavras-chave:
Múltiplas GPUs, Aplicações filtro-fluxo, Arquiteturas Heterogêneas
1 - Introdução
O desenvolvimento de novas tecnologias tem sido caracterizado pela geração de dados em massa. O crescimento contínuo dos dados, associado com um processamento mais sofisticado em diferentes áreas, tem impusionado avanços significativos nas arquiteturas de computação, refletindo em sistemas de armazenamento mais eficientes, assim como o uso de diferentes tipos de unidades de processamento, nas chamadas arquiteturas heterogêneas. Um exemplo dessas novas arquiteturas são os computadores com múltiplos processadores (arquitetura multicore) e placas gráficas (utilizando a arquitetura CUDA [12], por exemplo). Neste contexto, em adição para as tradicionais interfaces de programação paralela multicore [8,10], vemos recentemente a popularização de novas bibliotecas e ambientes [12,15,18] que permitem o desenvolvimento de aplicações em unidades de processamento alternativas como as Unidades de Processamento Gráfico (GPUs). Estes avanços tem sido essenciais para permitir que diferentes algoritmos explorarem o poder do processamento paralelo nessas novas arquiteturas, tornando-os viáveis para grandes volumes de dados.
      Apesar desses avanços, existem cenários em que uma única implementação paralela não é suficiente. Exemplos desses cenários são aplicações compostas de diferentes passos de processamento, como segmentação de imagens e descoberta de conhecimento em banco de dados [3], onde cada passo recebe uma determinada entrada e produz uma saída que será usada como entrada para outra etapa. Estas aplicações são tipicamente modeladas usando o paradigma filtro-fluxo [1], cujos passos do processamento são representados por filtros, que são instanciados em uma ou mais máquinas, e os dados que passam entre estes passos são representados pelo fluxo de dados (data streams). A eficiencia das aplicações implementadas usando o paradigma filtro-fluxo é alcançada, principalmente, pela distribuição paralela desses filtros, explorando de forma coordenada o conjunto de computadores interligados (computação em cluster). Consequentemente, a performace dessas aplicações está diretamente dependente de uma comunicação eficiente entre os filtros.
    Tradicionalmente, na execução de ambientes filtro-fluxo encontradas na literatura, a comunicação é feita principalmente utilizando o Message Passing Interface (MPI) [10]. O padrão MPI mostrou ser eficiente na maioria dos cenários de filtro-fluxo e pode ser aplicado à comunicação entre filtros instânciados na mesma máquina ou em diferentes máquinas. Entretanto, quando o cluster usado para executar uma aplicação possui máquinas heterogêneas, em que um filtro particular pode ser processado em uma GPU por exemplo, a comunicação via MPI entre os filtros pode exigir algum movimento extra de dados para ser concluída. Neste caso, os dados a serem transmitidos devem ser primeiro transferidos da memória global da GPU para a memória principal do computador e, em seguida, enviados via MPI para o filtro de destino. Movimento similar pode ocorrer no filtro de destino se este também for processado em uma GPU. Estes movimentos extras entre memória das unidades de processamento pode comprometer a performace da aplicação. Até onde conhecemos, nenhum ambiente de programação paralela de filtro-fluxo permite a comunicação direta entre GPUs.
    A fim de evitar estes movimentos excecivos, as GPUs responsáveis pelo processamento dos filtros precisam ser capazes de se comunicarem diretamente, sem precisar copiar os dados para a memória da CPU. Na literatura existem estratégias que fazem essa comunicação direta entre GPUs ser possível, como por exemplo: (i) GPUDirect RDMA [14] para transferir dados entre GPUs localizadas em uma mesma máquina; (ii) Cuda Aware MPI (OpenMPI + GPUDirect RDMA) [19] focada principalmente na comunicação entre GPUs em diferentes máquinas. Além disso, no cenário filtro-fluxo, essa comunicação direta é um grande desafio, uma vez que os filtros podem ser instanciados na mesma máquina ou em máquinas diferentes, tornando o programador responsável por controlar onde cada filtro é instanciado e decidindo qual a estratégia a ser usada para executar a comunicação entre os filtros executando em diferentes GPUs.  Além de ser um controle manual para o programador, é uma abordagem que precisa ser ajustada e reimplementada a cada nova configuração de local de filtro.
	Portanto, neste trabalho propomos uma abstração genérica para troca de dados direta entre GPUs em cenários filtro-fluxo. Nossa proposta torna transparente para o programador os detalhes de implementação de baixo nível relacionados à comunicação GPU e além disso retira do programador a responsabilidade de controlar a localizados dos filtros e de escolher qual estratégia de comunicação utilizar. Consolidamos nossa proposta como um framework filtro-fluxo, que também fornece um API para auxiliar na implementação dos filtros, bem como estabelecendo um padrão para representar o fluxo de dados entre os filtros. Em nossa avaliação, nós primeiro comparamos diferentes estratégias de comunicação entre GPUs, tanto intra-node (GPUs em um mesmo computador) quanto inter-node (GPUs em computadores diferentes), com objetivo de justificar as escolhas feitas para o framework. Então, avaliamos a eficiencia de nossa poposta implementando uma aplicação real usando nosso framework. Comparando esta implementação com uma usando diretamente as tecnologias existentes para alterar dados entre GPUs, mostramos que o tempo da aplicação real é o mesmo para ambas implementações.Este fato demonstra que nossa proposta, além de fornecer uma camada de abstração para facilitar o processo de programação, bem como controlar automaticamente a instanciação dos filtros, não compromete a performace da aplicação, que corresponde à nossa maior contribuição.

2 - Trabalhos relacionados
	O paradigma filtro-fluxo [1] é uma ferramenta importante para auxiliar o desenvolvimento eficiente de uma variedade de aplicações, tais como segmentação de imagem e descoberta de conhecimento em banco de dados [3], em sistemas distribuídos. Este paradigma é apto à trabalhar, de forma corrdenada, com um conjunto de computadores interligados (computação em cluster), explorando a performace individual de cada computador, como também a contribuição paralela entre eles. Para modelar  uma aplicação no paradigma filtro-fluxo, os estágios são representados por filtros que podem ser instanciados em um ou mais computadores. Por sua vez, o fluxo consiste da comunicação entre os filtros, enviando e recebendo dados relacionados àos diferentes estágios da aplicação. Neste trabalho, estamos focados em uma solução para este nicho de aplicação.
	Podemos encontrar na literatura varias propostas de ambientes que fornecem eficientes ferramente para lidar com diferentes desafios relacionados à implementação desta categoria de aplicação, taís como gerenciamento de instanciação de filtros, comunicação entre filtros, etc [9,6,2]. No citede2011watershed é apresentado o Watershed, um ambiente filtro-fluxo que fornece uma API C++ para a implementação de cada filtro. Além disso, a troca de dados entre filtros pode ser descrita usando arquivos XML (eXtensible Markup Language). Além do mais, nestes arquivos XML é possível configurar quais computadores serão responsáveis por executar cada filtro. Assim sendo, Wathershed consiste em um ambiente completo de execução em que os programadores podem apenas carregar os arquivos de configuração e os filtros implementados, toda a execução é realizada de forma transparente. Proposta similar é apresentada em [6], o Datacuter, com praticamente as mesmas funcionalidades. Finalmente, em [2], é proposto um sistema que permite salvar o estado das aplicações em sistemas distribuídos, explorando configurações dinâmicas em um cluster. Neste artigo, não estamos propondo um ambiente completo como os descritos neste parágrafo. Entretanto, nossa abstração genérica para troca direta de dados entre GPUs em cenários filtro-fluxo pode ser adaptada para estes propositos.
	Recentemente, a paralelização de aplicações utilizando GPUs tem sido apresentada  como uma área promissora de pesquisa [13,11,5,17]. Apesar disso, em cenários de aplicação filtro-fluxo, pelo que conhecemos, não encontramos frameworks de execução filtro-fluxo que permitem uso das GPUs. Isso ocorre devido as limitações relacionadas à tecnologias existentes para compartilhar dados de forma eficiente entre diferente s GPUs: a necessidade de detalhes de implementação de baixo nível relacionados à comunicação GPU e a complexidade para controlar a instanciação de filtros. Aqui estão, basicamente, duas maneiras diferentes para lidar com essa questão: (1) estrategias intra-node; que são exclusivamente focadas no compartilhamento de dados entre GPUs presentes em um mesmo computador [7,16,20]; e (2) estratégias inter-node, focada em soluções para GPUs presentes em diferentes computadores [14,4,19].
	A respeito das estratégias intra-node, uma tecnologia comum utilizada é a Unified Virtual Adressing (UVA), que permite diferentes unidades de processamento (ou seja, CPU e GPU) acessarem o mesmo espaço de endereço de memória, reduzindo o total de cópias de memória. Em [16] é apresentado uma otimização na qual os dados que estão em diferetes espaços de endereço são encapsulados em um único objeto com o objetivo de melhorar a performace de aplicações com intenso acesso à memoria. Além disso, em [20],os autores apresentam um novo sistema para realocar memoria em clusters baseado em um conceito de único espaço de endereço. Recentemente, a implementação deste conceito especificamente para alteração de dados entre GPUs foi melhorado pela GPUDirect RDMA [14], uma nova tecnologia que permitiu a troca de dados diretamente pelo barramento da PCI Express. Em [7] os autores apresentam um estudo detalhado da performace desta tecnologia. Usando aplicações reais, como aplicações de processamento de imagens e simulações matemáticas, diferentes aspectos são avaliados em que as aplicações obtiveram bons resultados em termos de eficienca, associados com uma implementação simples.
	As abordagens relacionadas ao inter-node [4,19] são baseadas em uma combinação da tecnologia GPUDirect RDMA e implementações do padrão MPI [10], tal como o OpenMPI (ou seja, Cuda-aware MPI). Nessas abordagens, em vez de utilizar o barramento PCI Express para troca de dados entre GPUs, a interface de rede é utilizada e o processo de comunicação entre diferentes computadores é realizado pelo OpenMPI.Em [4], os autores preparam um teste que foi usado com o fim de avaliar diferentes estradegias para transferencia de dados entre GPUs presentes em diferentes computadores. A avaliação foi realizada em um cluster de banda infinita e os resultados mostram que a combinação da tecnologia GPUDirect RDMA e OpenMPI acrescentou 50% mais eficiencias comparadas as outras estratégias.
	Neste trabalho propomos e avaliamos uma abstração genérica para troca direta de dados entre GPUs em cenários filtro-fluxo que visa controlar onde cada filtro é instanciado, decidindo qual estratégia será usada para melhorar a comunicação.

3 - Framework
	Nesta seção detalhamos nossa proposta de uma abstração genérica para troca direta de dados entre GPUs em cenários filtro-fluxo que é consolidada em um framework. Primeiro apresentamos uma visão geral da arquitetura do nosso framework, seguido por detalhes relacionados à API proposta para auxiliar na implementação e configuração dos filtros. Finalmente, descrevemos a estrutura do framework.
3.1 - Visão geral
	[FOTINHAS]
	Na figura [1](a) apresentamos a aplicação que será ustilizada como um exemplo de base para discução nesta seção. Esta aplicação contém quatro filtros. O primeiro filtro carrega os dados e realiza o processamento inicial. Depois, os dados são enviados para os filtros 2 e 3, que realizam um processamento independente nestes mesmo conjunto de dados de entrada. Neste ponto,  estes filtros podem ser executados em paralelo, uma vez que o processamento de dados é independente. Além disso, a troca de dados realizada pelos filtros 1 e 2 é local, enquanto que a troca de dados entre os filtros 2 e 3 dependem de tranferencias na rede. Quando estes filtros terminam de processar seus dados, eles são enviados para o último filtro, que realiza a operação final nos dados recebidos. Este último filtro depende de mais de um dos filtros anteriores (2 e 3), por isso é necessário esperar por todos os filtros anteriores para enviar seus dados. Também observe que cada filtro pode executar pré ou pós operações de processamento, enquanto ele espera os dados chegarem ou  depois que estes dados são enviados para o próximo.
	O framework é separado entre duas partes principais. Primeiro, nos temos uma API, que provê uma biblioteca de funções definidas para comunicação entre os filtros, bem como um arquivo de configuração XML para ser usado pelo programador para definir os ambientes de execução (ou seja, os filtros, o diretório onde os filtros estão armazenados, os endereços de IP das máquinas disponíveis e o número de GPUs disponíveis em cada uma dessas máquinas). Toda essa configuração é usada pela estrutura do framework , que é responsável por compilar, alocar e executar os filtros da aplicação. Depois 
