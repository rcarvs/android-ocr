Resumo
A geração de dados em massa tem impulsionado avanços nas arquiteturas de computação, refletindo nas arquiteturas heterogênias, compostas por diferentes tipos de unidades de processamento. O paradigma filter-stream é tipicamente usado para explorar o poder de processamento paralelo de novas arquiteturas e a eficiencia das aplicações é alcançada explorando, de forma coordenada, um grupo de computadores interligados (cluster) usando filtros e comunicação entre eles. Neste trabalho propomos implementar e testar uma abstração genérica para a troca de dados direta e transparente de aplicações filter-stream em cluster heterogênio com múltiplas arquiteturas GPU (Unidade de Processamento Gráfico). Esta abstração permite que todos os detalhes de implementação de baixo nível relacionados à comunicação da GPU e o controle relacionado à localização dos filtros sejam realizados de forma transparente para os programadores. Este trabalho está consolidado em um framework e nossos resultados de avaliação mostram que ele fornece uma camada de abstração sem comprometer o desempenho geral da aplicação. 
Abrstract
The massive data generation has been pushing for significant advances in computing architectures, reflecting in heterogeneous architectures, composed by different types of processing units. The filter-stream paradigm is typically used to exploit the parallel processing power of these new architectures and the efficiency of applications is achieved by exploring in a coordinated way a set of interconnected computers (cluster) using filters and communication between them. In this work we propose, implement and test a generic abstraction for direct and transparent data exchange of filter-stream applications in heterogeneous cluster with multi-GPU (Graphics Processing Units) architectures. This abstraction allows all the low-level implementation details related to GPU communication and the control related to the location of the filters to be performed transparently to the programmers. This work is consolidated in a framework and our evaluation results show that it provides an abstraction layer without compromising the overall application performance.
Palavras-chave:
Múltiplas GPUs, Aplicações filter-stream, Arquiteturas Heterogêneas
1 - Introdução
O desenvolvimento de novas tecnologias tem sido caracterizado pela geração de dados em massa. O crescimento contínuo dos dados, associado com um processamento mais sofisticado em diferentes áreas, tem impusionado avanços significativos nas arquiteturas de computação, refletindo em sistemas de armazenamento mais eficientes, assim como o uso de diferentes tipos de unidades de processamento, nas chamadas arquiteturas heterogêneas. Um exemplo dessas novas arquiteturas são os computadores com múltiplos processadores (arquitetura multicore) e placas gráficas (utilizando a arquitetura CUDA [12], por exemplo). Neste contexto, em adição para as tradicionais interfaces de programação paralela multicore [8,10], vemos recentemente a popularização de novas bibliotecas e ambientes [12,15,18] que permitem o desenvolvimento de aplicações em unidades de processamento alternativas como as Unidades de Processamento Gráfico (GPUs). Estes avanços tem sido essenciais para permitir que diferentes algoritmos explorarem o poder do processamento paralelo nessas novas arquiteturas, tornando-os viáveis para grandes volumes de dados.
      Apesar desses avanços, existem cenários em que uma única implementação paralela não é suficiente. Exemplos desses cenários são aplicações compostas de diferentes passos de processamento, como segmentação de imagens e descoberta de conhecimento em banco de dados [3], onde cada passo recebe uma determinada entrada e produz uma saída que será usada como entrada para outra etapa. Estas aplicações são tipicamente modeladas usando o paradigma filter-stream [1], cujos passos do processamento são representados por filtros, que são instanciados em uma ou mais máquinas, e os dados que passam entre estes passos são representados pelo fluxo de dados (data streams). A eficiencia das aplicações implementadas usando o paradigma filter-stream é alcançada, principalmente, pela distribuição paralela desses filtros, explorando de forma coordenada o conjunto de computadores interligados (cluster computing). Consequentemente, a performace dessas aplicações está diretamente dependente de uma comunicação eficiente entre os filtros.
    Tradicionalmente, na execução de ambientes filter-stream encontradas na literatura, a comunicação é feita principalmente utilizando o Message Passing Interface (MPI) [10]. O padrão MPI mostrou ser eficiente na maioria dos cenários de filter-stream e pode ser aplicado à comunicação entre filtros instânciados na mesma máquina ou em diferentes máquinas. Entretanto, quando o cluster usado para executar uma aplicação possui máquinas heterogêneas, em que um filtro particular pode ser processado em uma GPU por exemplo, a comunicação via MPI entre os filtros pode exigir algum movimento extra de dados para ser concluída. Neste caso, os dados a serem transmitidos devem ser primeiro transferidos da memória global da GPU para a memória principal do computador e, em seguida, enviados via MPI para o filtro de destino. Movimento similar pode ocorrer no filtro de destino se este também for processado em uma GPU. Estes movimentos extras entre memória das unidades de processamento pode comprometer a performace da aplicação. Até onde conhecemos, nenhum ambiente de programação paralela de filter-stream permite a comunicação direta entre GPUs.
    A fim de evitar estes movimentos excecivos, as GPUs responsáveis pelo processamento dos filtros precisam ser capazes de se comunicarem diretamente, sem precisar copiar os dados para a memória da CPU. Na literatura existem estratégias que fazem essa comunicação direta entre GPUs ser possível, como por exemplo: (i) GPUDirect RDMA [14] para transferir dados entre GPUs localizadas em uma mesma máquina; (ii) Cuda Aware MPI (OpenMPI + GPUDirect RDMA) [19] focada principalmente na comunicação entre GPUs em diferentes máquinas. Além disso, no cenário filter-stream, essa comunicação direta é um grande desafio, uma vez que os filtros podem ser instanciados na mesma máquina ou em máquinas diferentes, tornando o programador responsável por controlar onde cada filtro é instanciado e decidindo qual a estratégia a ser usada para executar a comunicação entre os filtros executando em diferentes GPUs.  Além disso 
